{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание датасета:\n",
    "\n",
    "The data set consists of paper reviews sent to an international conference mostly in Spanish (some are in English). It has a total of N = 405 instances evaluated with a 5-point scale ('-2': very negative, '-1': negative, '0': neutral, '1': positive, '2': very positive), expressing the reviewer's opinion about the paper and the orientation perceived by a reader who does not know the reviewer's evaluation (more details in the attributes' section). The distribution of the original scores is more uniform in comparison to the revised scores. This difference is assumed to come from a discrepancy between the way the paper is evaluated and the way the review is written by the original reviewer. \n",
    "\n",
    "The data set is stored in JSON format, the structure is as follows: \n",
    "Paper: { \n",
    "papers have an associated timespan and a paper ID, each paper contains some reviews. The reviews have their own ID, the review text, the remarks (which can be empty), the language of the review, its orientation and evaluation. \n",
    "\n",
    "Some relevant statistics (excluding reviews in English and empty reviews): \n",
    "- Number of words: \n",
    "Min: 3 Max: 530 Avg: 88.64 Stdev: 69.76 \n",
    "- Number of sentences: \n",
    "Min: 1 Max: 47 Avg: 8.91 Stdev: 7.54\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Timespan (datetime): A date associated with the year of conference, which in turn corresponds with the time the review was written. The data set includes four years of reviews worth of conferences. \n",
    "2. Paper ID (integer): This number identifies each individual paper from a given conference. The data set has 172 different papers. \n",
    "3. Preliminary decision (label): The preliminary decision of acceptance or rejection of a paper taken by the conference committee. \n",
    "4. Review ID (integer: A serial number identifier for each review as a correlative with respect to each individual paper. (e.g. the second review of some paper would correspond to the number $2$). The data set has a total of 405 reviews. Most papers have 2 reviews each. \n",
    "5. Text (text): Comments and detailed review of the paper. This is read by the authors and the editing commission of the conference. The editors determine if the paper should be published or not depending on the reviews. There are $6$ instances of empty reviews. \n",
    "6. Remarks (text): Additional comments that can be read only by the editing commission of the conference. This is used in conjunction with the previous attribute to determine if the paper should be published. This is an optional attribute. Whenever it is possible it is concatenated at the end of the main body of the review. Some reviews do not have remarks, this is indicated with an empty string ''. \n",
    "7. Language (text): Language corresponding to the review (it may be English or Spanish). In this case the majority of the reviews are in Spanish, with only $17$ instances of English reviews. \n",
    "8. Orientation (integer from -2 to 2): Review classification defined by the authors of this study, according to the 5-point scale previously described, obtained through the authors' systematic judgement of each review. This attribute represents the subjective perception of each review (i.e. how negative or positive the review is perceived when someone reads it). \n",
    "9. Evaluation (integer from -2 to 2): Review classification as defined by the reviewer, according to the 5-point scale previously described. This attribute represents the real evaluation given to the paper, as determined by the reviewers. \n",
    "10. Confidence (integer from 1 to 5): Value describing the confidence of the reviewer, a higher value denotes more confidence, while a lower value indicates less confidence.\n",
    "\n",
    "Источник: http://archive.ics.uci.edu/ml/datasets/Paper+Reviews\n",
    "\n",
    "## Задача\n",
    "Предсказать evaluation (от -2 до 2) по тексту ревью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>preliminary_decision</th>\n",
       "      <th>review__confidence</th>\n",
       "      <th>review__evaluation</th>\n",
       "      <th>review__id</th>\n",
       "      <th>review__lan</th>\n",
       "      <th>review__orientation</th>\n",
       "      <th>review__remarks</th>\n",
       "      <th>review__text</th>\n",
       "      <th>review__timespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>accept</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- El artículo aborda un problema contingente y...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El artículo presenta recomendaciones prácticas...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- El tema es muy interesante y puede ser de mu...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>accept</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se explica en forma ordenada y didáctica una e...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id preliminary_decision  review__confidence  review__evaluation  \\\n",
       "0  1.0               accept                 4.0                 1.0   \n",
       "1  NaN                  NaN                 4.0                 1.0   \n",
       "2  NaN                  NaN                 5.0                 1.0   \n",
       "3  2.0               accept                 4.0                 2.0   \n",
       "4  NaN                  NaN                 4.0                 2.0   \n",
       "\n",
       "   review__id review__lan  review__orientation review__remarks  \\\n",
       "0         1.0          es                  0.0             NaN   \n",
       "1         2.0          es                  1.0             NaN   \n",
       "2         3.0          es                  1.0             NaN   \n",
       "3         1.0          es                  1.0             NaN   \n",
       "4         2.0          es                  0.0             NaN   \n",
       "\n",
       "                                        review__text review__timespan  \n",
       "0  - El artículo aborda un problema contingente y...       2010-07-05  \n",
       "1  El artículo presenta recomendaciones prácticas...       2010-07-05  \n",
       "2  - El tema es muy interesante y puede ser de mu...       2010-07-05  \n",
       "3  Se explica en forma ordenada y didáctica una e...       2010-07-05  \n",
       "4                                                NaN       2010-07-05  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SpanishStemmer = SnowballStemmer('spanish')\n",
    "EnglishLemmatizer = WordNetLemmatizer()\n",
    "stopwords = {'en': set(stopwords.words('english')), 'es': set(stopwords.words('spanish'))}\n",
    "Count = CountVectorizer()\n",
    "Tfidf = TfidfVectorizer()\n",
    "clf_count = OneVsOneClassifier(LogisticRegressionCV())\n",
    "clf_tfidf = OneVsOneClassifier(LogisticRegressionCV())\n",
    "\n",
    "data = pd.read_csv('reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(subset=['review__text', 'review__evaluation']) # чистим данные от строчек без оценки или ревью\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data['review__evaluation']) # выделяем целевой столбец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, lan):\n",
    "    text = list(filter(lambda x: len(x) > 0, re.split('\\W+', text.lower()))) # разбиваем текст на слова\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if lan == 'es':\n",
    "            word = SpanishStemmer.stem(word)\n",
    "            # приводим слова к основе для большей точности (приличного лемматизатора для испанского я не нашла :( )\n",
    "        elif lan == 'en':\n",
    "            word = EnglishLemmatizer.lemmatize(word) # лемматизируем слова\n",
    "        if word not in stopwords[lan]: # убираем стоп-слова\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "for row in data.iterrows(): # вытаскиваем тексты из датасета и препроцессим их\n",
    "    text = row[1]['review__text']\n",
    "    if row[1].notna()['review__remarks']:\n",
    "        text += row[1]['review__remarks']\n",
    "    lan = row[1]['review__lan']\n",
    "    X.append(preprocess_text(text, lan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articul abord problem contingent relev inclu tant diagnost nacional uso buen practic com solucion buen practic concret lenguaj adecu articul sient com concaten tres articul diferent 1 result encuest 2 buen practic segur 3 incorpor buen practic orden seccion ser mejor si reflej orden version revis 2 1 3 articul tien valid ningun tip siqu evalu expert',\n",
       " 'articul present recomend practic par desarroll softwar segur describ mejor practic recomend par desarroll softwar proactiv ataqu realiz analisis cost practic desarroll softwar tod bas revision practic propuest bibliograf contr dat obten encuest empres final recomiend gui ser ideal aplic gui propuest empres involucr encuest sirv par origin mod pod evalu efect form independient',\n",
       " 'tem interes pued ser much ayud gui par incorpor practic segur present descripcion etap uso 9 practic par desarroll softwar segur real desarroll softwar chil com indic pap pued logr sol 22 encuest total 50 present nuev tabl correspond practic par desarroll softwar segur per gui present 10 practic explic sugier mejor gui mayor aport secuenci incorpor propon ademas deb explic practic observ diferenci practic column deb dar sugerent com aplic text indic mas adel present ademas tres practic extras lei correct acuerd format pon com minim 5 palabr clav sugier mencion practic mostr cad tabl algun referent estan incomplet ejempl falt año referent 17 falt año tip event referent 11 falt editorial referent 19 libr algun titul llev com dentr comill ejempl referent 1',\n",
       " 'explic form orden didact experient uso tic par colabor academ original trabaj dimension fuert ver trabaj larg dat com gorton et 1997 actual com lanunil et 2010 embarg relev tem com patron referent activ relacion tesis cientif asoci buen present hac aport sugier mir public revist compar eficient efect activ apoy herramient versus actual realid herramient ejempl pregunt posibl respond analisis exploratori principal activ dond uso herramient colabor clav cambi diseñ herramient deb desarroll futur exist perfil estudi academ mas propici par adopcion plataform referent gorton i hawryszkiewycz i and ragoonad k 1997 collaborativ tools and process to support softwar engineering shift work bt technology journal 15 3 jul 1997 189 198 filipp lanubil christof ebert rafael prikladnicki auror vizcain collaboration tools for global softwar engineering ieee softwar vol 27 2 pp 52 55 mar apr 2010',\n",
       " 'autor describ metodolog par desarroll form colabor tesis memori usand tecnolog usan habitual desarroll softwar asim describ herramient concret bondad com ejempl latex git final propon fluj trabaj par desarroll proyect naturalez valor principal articul radic aplic conoc estudi domin dec tecnic herramient desarroll softwar problemat diferent com cas tesis memori tod ello afan hac mas eficient proces 1 enfasis articul solucion hac analisis detall problem pretend resolv palabr respuest siguient pregunt exact problem b impact gener problem c import resolv problem d solucion implement hast fech ventaj tien solucion propuest respect anterior 2 opinion articul deb enfatiz mas metodolog fluj trabaj ejempl añad diagram utiliz lenguaj visual permit lad comprend proces general desarroll tesis distingu rol activ tecnolog asoci cad fas memori 3 deb cuid algun aspect lenguaj rigor ciert afirm com ejempl dad mas bien atroz ortograf goz ingenier autor dispon algun respald empir par respald afirm necesari recurr lenguaj tan prosaic par justific convenient usar determin herramient tecnolog proposit recom revis expresion public punt 3 1 ten acces direct punt 3 2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация текстов\n",
    "\n",
    "Воспользуемся двумя векторизаторами - первый считает кол-во вхождений слова в текст, второй - tf-idf для слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = Count.fit_transform(X_train)\n",
    "X_test_count = Count.transform(X_test)\n",
    "X_train_tfidf = Tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = Tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_count.fit(X_train_count, y_train)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_test_predicted_labels_count = clf_count.predict(X_test_count)\n",
    "\n",
    "y_test_predicted_labels_tfidf = clf_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper introduces segmentation procedure breast tissue image using svm general comment concerning proposed approach segmentation method introduced considers local color gray value information perhaps introducing feature related membrane local e g membrane ha symmetry property exploited global e g continuity approximately circular shape property may improve segmentation result feature selection also key component improve performance use feature selection procedure b concerning experimentation describe experiment sufficient detail others replicate make data publicly available b explain selected classifier parameter parameter selection svm critical may improve notably performance join fig 10 9 single plot better see difference provide qualitative segmentation result fig 12 14 15 quantitative result also important specially come comparison quantitatively compare algorithm competing work literature c concerning paper organization paper well written clearly introduces problem describes relevant literature present solution comment concerning paper organization problem statement literature review intro theoretical framework section opinion bit long compared important section e g feature extraction experimentation one paragraph b although english general correct small mistake could solved read professional c two proposed method section well written paper good literature review show preliminary result\n",
      "True label:\t2.0\n",
      "Predicted label with count vectorizer:\t1.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n",
      "articul abord problem relev bog comun p ej cmmi acq arte revis intent previ resolv problem definicion patron proyect adquisicion deb ceñ definicion usual patron maxim si comp patron diseñ com hac conclusion p ej estil portland patron diseñ reconoc context problem solucion tecnic utiliz mect parec adecu par constru taxonom per patron exclu consider sobr causal etc articul parec asum patron diseñ patron form referent 13 list mal nombr autor\n",
      "True label:\t-2.0\n",
      "Predicted label with count vectorizer:\t1.0\n",
      "Predicted label with tf-idf vectorizer:\t0.0\n",
      "\n",
      "pap segun revisor contempl direct contribu cientif embarg experient tem trat interes present congres pes pued ser present com pap regul congres ser recomiend acept articul par present workshop educ infonor 2013 estim revisor\n",
      "True label:\t1.0\n",
      "Predicted label with count vectorizer:\t1.0\n",
      "Predicted label with tf-idf vectorizer:\t1.0\n",
      "\n",
      "trabaj present metodolog par abord complej implement regl negoci realiz cambi funcional bas sistem propon metodolog clar bas document mediant plantill par manej analiz impact realiz implement regl negoci via orient aspect razon present par indic enfoqu oa par encapsul conexion regl negoci funcional bas tare trivial general deb ser abord mayor profund present evident formal utiliz plantill propuest resuelv form concret problem sugier present problem resuelt medi herramient encuentr desarroll manej automat plantill defect demostr aplic problem especif\n",
      "True label:\t0.0\n",
      "Predicted label with count vectorizer:\t1.0\n",
      "Predicted label with tf-idf vectorizer:\t1.0\n",
      "\n",
      "resum trabaj describ tres activ docent curs elect univers seren desarroll interpret usand herramient antlr andro principal conexion activ primer activ implement pars interpret par calcul segund activ incorpor habil orden list interpret ultim activ incorpor servici reconoc voz usand libr googl acuerd trabaj result activ permit alumn comprend mejor maner concept lenguaj formal evalu general trabaj describ maner clar com realiz activ curs elect embarg desd punt vist trabaj present dos grand debil 1 principal motiv trabaj uso herramient antlr util par curs lenguaj formal obstant nunc ofrec muestr ciert afirm sol detall com implement softwar activ fuertement recomend dar real señal ej justif experiment etc herramient ayud docenci topic 2 punt caus punt anterior motiv problem clar muestr neces usar herramient par curs lenguaj si autor logr encontr motiv clar medibl punt 1 pued ser resuelt final trabaj logr convenc conclusion comentari menor 1 trabaj exced numer maxim exig pagin 9 8 pagin 2 conclusion afirm uso antlr andro conoc lenguaj formal pued igual herramient siri apple googl now opinion afirm verdader porqu par resolv activ usan apis googl signific product googl activ pued llev cab resum antlr conoc lenguaj formal suficient par constru googl now 3 ser agrad usar referent canon dsls cambi usad trabaj articl vandeurs 2000 dla 352029 352035 author van deurs ari and klint paul and viss joost titl domain specific languag an annotat bibliography journal sigpl not issue_dat jun 2000 volum 35 numb 6 month jun year 2000 issn 0362 1340 pag 26 36 numpag 11 url http doi acm org 10 1145 352029 352035 doi 10 1145 352029 352035 acmid 352035 publish acm address new york ny usa articl mernik 2005 ddl 1118890 1118892 author mernik marj and heering jan and sloan anthony m titl when and how to develop domain specific languag journal acm comput surv issue_dat decemb 2005 volum 37 numb 4 month dec year 2005 issn 0360 0300 pag 316 344 numpag 29 url http doi acm org 10 1145 1118890 1118892 doi 10 1145 1118890 1118892 acmid 1118892 publish acm address new york ny usa keywords domain specific languag application languag domain analysis languag development system 4 text asoci memori titul aport much trabaj 5 pequeñ error ortograf deb ser correg\n",
      "True label:\t-1.0\n",
      "Predicted label with count vectorizer:\t-2.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    text = X_test[i]\n",
    "    print(text)\n",
    "    print('True label:\\t{}\\nPredicted label with count vectorizer:\\t{}\\nPredicted label with tf-idf vectorizer:\\t{}\\n'.format(\n",
    "        y_test[i], y_test_predicted_labels_count[i], y_test_predicted_labels_tfidf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count accuracy score: 0.36\n",
      "Tf-idf accuracy score: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(f'Count accuracy score: {accuracy_score(y_test, y_test_predicted_labels_count)}')\n",
    "print(f'Tf-idf accuracy score: {accuracy_score(y_test, y_test_predicted_labels_tfidf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1., -2.,  2.,  2., -2.,  2.,  2.,  0., -2.,  2.,\n",
       "        2.,  2., -1.,  2., -2.,  2., -2., -2.,  1., -2.,  1.,  2., -2.,\n",
       "        2., -2., -2., -2.,  2.,  2.,  2., -2., -2.,  2.,  2.,  0.,  1.,\n",
       "        1.,  2.,  1., -1.,  1.,  0.,  2., -2.,  0.,  2.,  2.,  2.,  2.,\n",
       "        2.,  0.,  1.,  0., -2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,\n",
       "        2.,  2.,  1.,  2.,  0.,  1.,  2.,  1., -2.,  2.,  0.,  1.,  2.,\n",
       "        1.,  2., -2.,  2., -2.,  1.,  2., -2.,  1.,  2., -1.,  2.,  1.,\n",
       "        2.,  0.,  0.,  2.,  2.,  2.,  2.,  1., -2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "3\n",
      "10\n",
      "21\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for i in range(-2, 3):\n",
    "    print(list(y_test_predicted_labels_count).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "0\n",
      "16\n",
      "22\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "for i in range(-2, 3):\n",
    "    print(list(y_test_predicted_labels_tfidf).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

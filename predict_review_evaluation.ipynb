{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание датасета:\n",
    "\n",
    "The data set consists of paper reviews sent to an international conference mostly in Spanish (some are in English). It has a total of N = 405 instances evaluated with a 5-point scale ('-2': very negative, '-1': negative, '0': neutral, '1': positive, '2': very positive), expressing the reviewer's opinion about the paper and the orientation perceived by a reader who does not know the reviewer's evaluation (more details in the attributes' section). The distribution of the original scores is more uniform in comparison to the revised scores. This difference is assumed to come from a discrepancy between the way the paper is evaluated and the way the review is written by the original reviewer. \n",
    "\n",
    "The data set is stored in JSON format, the structure is as follows: \n",
    "Paper: { \n",
    "papers have an associated timespan and a paper ID, each paper contains some reviews. The reviews have their own ID, the review text, the remarks (which can be empty), the language of the review, its orientation and evaluation. \n",
    "\n",
    "Some relevant statistics (excluding reviews in English and empty reviews): \n",
    "- Number of words: \n",
    "Min: 3 Max: 530 Avg: 88.64 Stdev: 69.76 \n",
    "- Number of sentences: \n",
    "Min: 1 Max: 47 Avg: 8.91 Stdev: 7.54\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Timespan (datetime): A date associated with the year of conference, which in turn corresponds with the time the review was written. The data set includes four years of reviews worth of conferences. \n",
    "2. Paper ID (integer): This number identifies each individual paper from a given conference. The data set has 172 different papers. \n",
    "3. Preliminary decision (label): The preliminary decision of acceptance or rejection of a paper taken by the conference committee. \n",
    "4. Review ID (integer: A serial number identifier for each review as a correlative with respect to each individual paper. (e.g. the second review of some paper would correspond to the number $2$). The data set has a total of 405 reviews. Most papers have 2 reviews each. \n",
    "5. Text (text): Comments and detailed review of the paper. This is read by the authors and the editing commission of the conference. The editors determine if the paper should be published or not depending on the reviews. There are $6$ instances of empty reviews. \n",
    "6. Remarks (text): Additional comments that can be read only by the editing commission of the conference. This is used in conjunction with the previous attribute to determine if the paper should be published. This is an optional attribute. Whenever it is possible it is concatenated at the end of the main body of the review. Some reviews do not have remarks, this is indicated with an empty string ''. \n",
    "7. Language (text): Language corresponding to the review (it may be English or Spanish). In this case the majority of the reviews are in Spanish, with only $17$ instances of English reviews. \n",
    "8. Orientation (integer from -2 to 2): Review classification defined by the authors of this study, according to the 5-point scale previously described, obtained through the authors' systematic judgement of each review. This attribute represents the subjective perception of each review (i.e. how negative or positive the review is perceived when someone reads it). \n",
    "9. Evaluation (integer from -2 to 2): Review classification as defined by the reviewer, according to the 5-point scale previously described. This attribute represents the real evaluation given to the paper, as determined by the reviewers. \n",
    "10. Confidence (integer from 1 to 5): Value describing the confidence of the reviewer, a higher value denotes more confidence, while a lower value indicates less confidence.\n",
    "\n",
    "Источник: http://archive.ics.uci.edu/ml/datasets/Paper+Reviews\n",
    "\n",
    "## Задача\n",
    "Предсказать evaluation (от -2 до 2) по тексту ревью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>preliminary_decision</th>\n",
       "      <th>review__confidence</th>\n",
       "      <th>review__evaluation</th>\n",
       "      <th>review__id</th>\n",
       "      <th>review__lan</th>\n",
       "      <th>review__orientation</th>\n",
       "      <th>review__remarks</th>\n",
       "      <th>review__text</th>\n",
       "      <th>review__timespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>accept</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- El artículo aborda un problema contingente y...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El artículo presenta recomendaciones prácticas...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- El tema es muy interesante y puede ser de mu...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>accept</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se explica en forma ordenada y didáctica una e...</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id preliminary_decision  review__confidence  review__evaluation  \\\n",
       "0  1.0               accept                 4.0                 1.0   \n",
       "1  NaN                  NaN                 4.0                 1.0   \n",
       "2  NaN                  NaN                 5.0                 1.0   \n",
       "3  2.0               accept                 4.0                 2.0   \n",
       "4  NaN                  NaN                 4.0                 2.0   \n",
       "\n",
       "   review__id review__lan  review__orientation review__remarks  \\\n",
       "0         1.0          es                  0.0             NaN   \n",
       "1         2.0          es                  1.0             NaN   \n",
       "2         3.0          es                  1.0             NaN   \n",
       "3         1.0          es                  1.0             NaN   \n",
       "4         2.0          es                  0.0             NaN   \n",
       "\n",
       "                                        review__text review__timespan  \n",
       "0  - El artículo aborda un problema contingente y...       2010-07-05  \n",
       "1  El artículo presenta recomendaciones prácticas...       2010-07-05  \n",
       "2  - El tema es muy interesante y puede ser de mu...       2010-07-05  \n",
       "3  Se explica en forma ordenada y didáctica una e...       2010-07-05  \n",
       "4                                                NaN       2010-07-05  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SpanishStemmer = SnowballStemmer('spanish')\n",
    "EnglishLemmatizer = WordNetLemmatizer()\n",
    "stopwords = {'en': set(stopwords.words('english')), 'es': set(stopwords.words('spanish'))}\n",
    "Count = CountVectorizer()\n",
    "Tfidf = TfidfVectorizer()\n",
    "clf_count = OneVsOneClassifier(LogisticRegressionCV())\n",
    "clf_tfidf = OneVsOneClassifier(LogisticRegressionCV())\n",
    "\n",
    "data = pd.read_csv('reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(subset=['review__text', 'review__evaluation']) # чистим данные от строчек без оценки или ревью\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(data['review__evaluation']) # выделяем целевой столбец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, lan):\n",
    "    text = list(filter(lambda x: len(x) > 0, re.split('\\W+', text.lower()))) # разбиваем текст на слова\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if lan == 'es':\n",
    "            word = SpanishStemmer.stem(word)\n",
    "            # приводим слова к основе для большей точности (приличного лемматизатора для испанского я не нашла :( )\n",
    "        elif lan == 'en':\n",
    "            word = EnglishLemmatizer.lemmatize(word) # лемматизируем слова\n",
    "        if word not in stopwords[lan]: # убираем стоп-слова\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "for row in data.iterrows(): # вытаскиваем тексты из датасета и препроцессим их\n",
    "    text = row[1]['review__text']\n",
    "    if row[1].notna()['review__remarks']:\n",
    "        text += row[1]['review__remarks']\n",
    "    lan = row[1]['review__lan']\n",
    "    X.append(preprocess_text(text, lan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articul abord problem contingent relev inclu tant diagnost nacional uso buen practic com solucion buen practic concret lenguaj adecu articul sient com concaten tres articul diferent 1 result encuest 2 buen practic segur 3 incorpor buen practic orden seccion ser mejor si reflej orden version revis 2 1 3 articul tien valid ningun tip siqu evalu expert',\n",
       " 'articul present recomend practic par desarroll softwar segur describ mejor practic recomend par desarroll softwar proactiv ataqu realiz analisis cost practic desarroll softwar tod bas revision practic propuest bibliograf contr dat obten encuest empres final recomiend gui ser ideal aplic gui propuest empres involucr encuest sirv par origin mod pod evalu efect form independient',\n",
       " 'tem interes pued ser much ayud gui par incorpor practic segur present descripcion etap uso 9 practic par desarroll softwar segur real desarroll softwar chil com indic pap pued logr sol 22 encuest total 50 present nuev tabl correspond practic par desarroll softwar segur per gui present 10 practic explic sugier mejor gui mayor aport secuenci incorpor propon ademas deb explic practic observ diferenci practic column deb dar sugerent com aplic text indic mas adel present ademas tres practic extras lei correct acuerd format pon com minim 5 palabr clav sugier mencion practic mostr cad tabl algun referent estan incomplet ejempl falt año referent 17 falt año tip event referent 11 falt editorial referent 19 libr algun titul llev com dentr comill ejempl referent 1',\n",
       " 'explic form orden didact experient uso tic par colabor academ original trabaj dimension fuert ver trabaj larg dat com gorton et 1997 actual com lanunil et 2010 embarg relev tem com patron referent activ relacion tesis cientif asoci buen present hac aport sugier mir public revist compar eficient efect activ apoy herramient versus actual realid herramient ejempl pregunt posibl respond analisis exploratori principal activ dond uso herramient colabor clav cambi diseñ herramient deb desarroll futur exist perfil estudi academ mas propici par adopcion plataform referent gorton i hawryszkiewycz i and ragoonad k 1997 collaborativ tools and process to support softwar engineering shift work bt technology journal 15 3 jul 1997 189 198 filipp lanubil christof ebert rafael prikladnicki auror vizcain collaboration tools for global softwar engineering ieee softwar vol 27 2 pp 52 55 mar apr 2010',\n",
       " 'autor describ metodolog par desarroll form colabor tesis memori usand tecnolog usan habitual desarroll softwar asim describ herramient concret bondad com ejempl latex git final propon fluj trabaj par desarroll proyect naturalez valor principal articul radic aplic conoc estudi domin dec tecnic herramient desarroll softwar problemat diferent com cas tesis memori tod ello afan hac mas eficient proces 1 enfasis articul solucion hac analisis detall problem pretend resolv palabr respuest siguient pregunt exact problem b impact gener problem c import resolv problem d solucion implement hast fech ventaj tien solucion propuest respect anterior 2 opinion articul deb enfatiz mas metodolog fluj trabaj ejempl añad diagram utiliz lenguaj visual permit lad comprend proces general desarroll tesis distingu rol activ tecnolog asoci cad fas memori 3 deb cuid algun aspect lenguaj rigor ciert afirm com ejempl dad mas bien atroz ortograf goz ingenier autor dispon algun respald empir par respald afirm necesari recurr lenguaj tan prosaic par justific convenient usar determin herramient tecnolog proposit recom revis expresion public punt 3 1 ten acces direct punt 3 2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация текстов\n",
    "\n",
    "Воспользуемся двумя векторизаторами - первый считает кол-во вхождений слова в текст, второй - tf-idf для слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = Count.fit_transform(X_train)\n",
    "X_test_count = Count.transform(X_test)\n",
    "X_train_tfidf = Tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = Tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_count.fit(X_train_count, y_train)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_test_predicted_labels_count = clf_count.predict(X_test_count)\n",
    "\n",
    "y_test_predicted_labels_tfidf = clf_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend change paper title order according paper body review english grammar error founded review abstract doe mean doe mean utilized represent appropriateness utilized represent appropriateness introducction ha like first phase auscultating verb background systematic mapping study methodology used systematic mapping study methodology used existing research performance evaluation existing research performance evaluation dieste juristo work 10 deal work dieste juristo 10 deal methodology review use ly verb third question kind study doe use higher frequency certain construct appropriateness technique review type question structure classification schema order answer research question literature review focused literature mapping analysis result figure 1 en dcm format figure 1 en dcm format article paper conclusion future work reason necessary proposal carried help reason necessary carry proposal help figure careful figure title title must following figure type study paragraph figure 5 experimental paragraph experiment figure technique considered recommend performing mapping domain technique constructor show graphic result instead figure 8 recommend change title order reflect paper body\n",
      "True label:\t1.0\n",
      "Predicted label with count vectorizer:\t2.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n",
      "pap involucr desarroll aplic simul protocol bb84 apreci trabaj orden dud comprension algun concept fisic cuantic sustent criptograf cuantic com teorem clonacion principi superposicion entrelaz labor tien merit ademas apreci uso ingeni softwar construccion aplic aspect posit pues general cuand involucr creacion softwar are conoc fronter recurr cod and fix tod desventaj conllev cre manuscrit deb ser dirig are criptograf segur especial comput ambient distribu veo signific relev aport manuscrit usar rmi segun opinion contribu per pues rmi facil usar si manej jav embarg interoper soport lenguaj program ademas sistem bas rmi med crec tien problem rendimient mientr mas crec mas lent torn lad segun algun purist sistem client servidor sistem distribu segun cas client servidor cas mas basic comput distribu fin habl estrict desd are comput distribu veo relev are manuscrit embarg parec are pap podr ser pertinent trabaj orden clar bien escrit expert are criptograf per hac años atras oportun escuch seminari ingles habl criptograf cuantic mencion gran cantid simul aplic inclus dij ten aplic utiliz criptograf cuantic vari kilometr medi fibr optic entonc cre mejor evalu manuscrit are are grid sistem distribu pues are pap segun opinion tien aspect original usa aspect trivial principi client servidor com dich anterior pap tien mas asunt fisic cuantic criptograf comput distribu abstrayendom are compet veo uso tecnolog ambient distribu usad com client servidor interoper restriccion escal aspect posit pap apreci uso ingeni softwar respect are grid computing sistem distribu manuscrit contien aspect relev utiliz rmi par implement sistem client servidor obstant rmi facil usar com buen paradigm conoc comput performanc contrapon facil usar rmi escap porqu facil usar per tien escal document bien present quizas tabl 2 tabl 3 ser mejor fusion utiliz fil com comput column detall red sobr tod si mas esquem client servidor tien ejempl anill distribu clav cuantic mas 2 comput involucr cre present are criptograf segur ser mas pertinent\n",
      "True label:\t-2.0\n",
      "Predicted label with count vectorizer:\t1.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n",
      "desd punt vist red bayesian trabaj hac mas aplic direct implement geni algoritm k2 coop hervokits 1992 qued clar par va utiliz potencial model grafic probabilist nivel inferent clasif referent inclu list deb ser refin tien sent inclu referent años 90 aparezc coletill envi\n",
      "True label:\t0.0\n",
      "Predicted label with count vectorizer:\t2.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n",
      "trabaj excelent gui par implant dat cent bien escrit dond utiliz bibliograf conoc manual libr falt literatur especializ trabaj investig aplic original aplic interes empres mejor suger falt incorpor seccion trabaj relacion tambien med grad efect implant seccion analisis result prueb consider interes acept par congres infonor workshop aplic empresarial\n",
      "True label:\t0.0\n",
      "Predicted label with count vectorizer:\t2.0\n",
      "Predicted label with tf-idf vectorizer:\t2.0\n",
      "\n",
      "resum articul analiz conjunt estudi objet conoc piens investig sobr tecnic educ mas adecu evalu trabaj tien estructur pap propuest ve interes embarg aunqu trabaj discut consecuent result cre discut clar potencial caus tal vez pued obten conclusion interes exist divergent mencion qued clar quier ten convergent absolut sobr tecnic simpl vist da impresion conjunt tecnic aplic ciert context parec ser apropi background demasi cort par introduc concept necesari par comprend propuest relat work sum pobr sol 1 cit detall menor 1 nombr seccion 2 background sum ambigu vuelv dificil sab trat seccion sugier ser mas especif ej systematic review for elicitation techniqu 2 explic systematic mapping sol explic uso 3 habl met analisis met analisis parec pued contribu discusion 4 reemplaz authors we cuand amerit ej parraf 2 pagin 2 ocasion cuest sab si habl autor trabaj particul trabaj estan present 5 reemplaz you one you informal 6 estudi identif 42 estudi demasi estudi 7 text figur 3 separ imag 8 pagin blanc medi document 9 in order to mov in this direction this study aims auscultating how researchers represent the appropriateness of the techniqu direccion ambigu oracion\n",
      "True label:\t0.0\n",
      "Predicted label with count vectorizer:\t-2.0\n",
      "Predicted label with tf-idf vectorizer:\t-2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    text = X_test[i]\n",
    "    print(text)\n",
    "    print('True label:\\t{}\\nPredicted label with count vectorizer:\\t{}\\nPredicted label with tf-idf vectorizer:\\t{}\\n'.format(\n",
    "        y_test[i], y_test_predicted_labels_count[i], y_test_predicted_labels_tfidf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count accuracy score: 0.44\n",
      "Tf-idf accuracy score: 0.46\n"
     ]
    }
   ],
   "source": [
    "print(f'Count accuracy score: {accuracy_score(y_test, y_test_predicted_labels_count)}')\n",
    "print(f'Tf-idf accuracy score: {accuracy_score(y_test, y_test_predicted_labels_tfidf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
